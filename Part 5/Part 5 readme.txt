I'm not sure if I got this part right, but it's the bonus so I figured 
it was worth a shot. Using the kaggle link I included in part 4, I found
a .csv file with 7,788 features in it, which I would assume is a large
enough dataset to push the program to it's limits. Although the program
took significantly longer to run, this was to be assumed with such a large
training model. Theoretically I could run a few more large scale datasets
through this to gain more accuracy as well. 